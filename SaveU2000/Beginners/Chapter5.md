# Overview

- **Chapter 5: Nuts and Bolts in Machine Learning** 
  - 5.1: *Bias and Variance*
  - 5.2: *Regularlization*
    - L1 and L2 Regularization (aka weights regularization)
    - Dropout
    - Activity Regularization

----


### 5.1: Bias and Variance

 - Andrew Ng's ML Course https://www.coursera.org/lecture/deep-neural-network/bias-variance-ZhclI 
   - also on https://www.youtube.com/watch?v=SjQyLhQIXSM
   - and if you're a fan, here's Andrew Ng on the same topic a longer time ago https://www.courses.com/stanford-university/machine-learning/9 
 - Emily Fox's ML Course https://www.coursera.org/lecture/ml-regression/variance-and-the-bias-variance-tradeoff-ZvP40
 - https://www.learnopencv.com/bias-variance-tradeoff-in-machine-learning/
 - http://www.r2d3.us/visual-intro-to-machine-learning-part-2/
 - Yaser Abu-Mostafa's Caltech Course https://www.youtube.com/watch?v=zrEyxfl2-a8 (a little dense but if you come from the math/stats path, you might like it)
 - Sebastian Thrun explaining causually when in a self-driving car https://www.youtube.com/watch?v=W5uUYnSHDhM 
 - [A Modern Take on the Bias-Variance Tradeoff in NN](https://arxiv.org/pdf/1810.08591.pdf)
 - https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229
 
 
 
 https://www.ics.uci.edu/~smyth/courses/cs274/readings/xing_singh_CMU_bias_variance.pdf (hardcore math but good)
 https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/
 https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/
 https://machinelearningmastery.com/how-to-reduce-generalization-error-in-deep-neural-networks-with-activity-regularization-in-keras/
 https://www.oreilly.com/ideas/compressing-and-regularizing-deep-neural-networks
 https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607
